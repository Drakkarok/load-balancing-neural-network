
# Deep Q-Network for Web Application Load Balancing

This repository contains the implementation of a Deep Reinforcement Learning (DQN) Agent for Load Balancing in a containerized web application environment. This project is part of a Master's Dissertation at UPB (2025-2026).

## üöÄ Quick Start (Replication)

### 1. Prerequisites
*   **Docker Desktop** (Installed & Running) with Linux Containers enabled.
*   **Python 3.10+** (for running the Agent training script locally).

### 2. Setup Training Environment
The project runs as a hybrid:
*   **Docker**: Runs the Web Servers, Prometheus/Grafana (Monitoring), and Database (if any).
*   **Local Host**: Runs the `Agent` (Python script) to leverage GPU acceleration and easier debugging.

**Step 2.1: Create & Activate Python venv**
```bash
# Windows (PowerShell)
python -m venv venv
.\venv\Scripts\activate

# Mac/Linux
python3 -m venv venv
source venv/bin/activate
```

**Step 2.2: Install Dependencies**
```bash
pip install -r requirements.txt
```
*(Note: If `requirements.txt` is missing, install: `pip install torch numpy pandas requests matplotlib flask`)*

### 3. Start Infrastructure
Start the Docker containers (Web Servers, Trainer Backend, etc.).
```bash
# Stop old containers
docker compose down

# Build and start fresh (CRITICAL after any code changes)
docker compose up -d --build
```
*Wait ~10-15 seconds for containers to initialize.*

### 4. Run Training
Start the DQN Agent training process.
```bash
python Agent/train_dqn.py
```
This will:
*   Connect to the Dockerized environment (`localhost:8081-8084`).
*   Train for 6,000 episodes (Phase 1, 2, 3).
*   Save Checkpoints to `Models/checkpoints/`.
*   Save Metrics to `Models/metrics/`.

### üö® Resume Training (Important!)
If training is interrupted, you can resume from the last saved checkpoint (saved every 100 episodes):
```bash
python Agent/train_dqn.py --resume
```

---

## üõ†Ô∏è Scripts & Tools

| Script                      | Description                                                                                                                                                                          |
| :-------------------------- | :----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| **`Agent/train_dqn.py`**    | **Main Training Loop.** Runs the simulation, updates the neural network, and saves checkpoints. <br> **Flag:** `--resume` (Continue from last `.pth` file).                          |
| **`Agent/evaluate_dqn.py`** | **Testing Script.** Loads `dqn_final.pth` (or specific model) and runs 50 episodes *without* exploration to measure pure performance. <br> **Usage:** `python Agent/evaluate_dqn.py` |
| **`Agent/visualize.py`**    | **Plotting Script.** Reads `Models/metrics/training_metrics.csv` and generates learning curve plots in `Models/metrics/plots/`. <br> **Usage:** `python Agent/visualize.py`          |
| **`Agent/app.py`**          | **Agent API.** The Flask app that manages the environment. (Imported by `train_dqn.py`, normally not run manually).                                                                  |

---

## üèóÔ∏è Architecture & Optimizations

This system has been heavily optimized for **Windows Docker Desktop** environments:

*   **Parallel Execution**: The Agent talks to all 3 servers concurrently (using `ThreadPoolExecutor`) to minimize tick latency.
*   **Persistent Connections**: Uses `requests.Session()` with connection pooling to prevent TCP socket exhaustion on Windows.
*   **CPU Throttling**: The training loop includes a `0.05s` throttle to prevent CPU starvation of the Docker network daemon.
*   **Robust Logging**: Errors are logged to `Models/logs/training_errors.log` instead of crashing the process.

## üìä Outputs

*   **Checkpoints**: `Models/checkpoints/dqn_episode_XXXX.pth`
*   **Metrics CSV**: `Models/metrics/training_metrics.csv` (Reward, Gini, Accuracy per 10 episodes)
*   **Plots**: `Models/metrics/plots/` (Generated by `visualize.py`)

## üßπ Cleanup
To stop everything and free resources:
```bash
docker compose down
```